{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eager.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CCQY7jpBfMur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "z6X9omPnfO_h",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2QQJJyDzqGRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Eager Execution\n"
      ]
    },
    {
      "metadata": {
        "id": "B1xdylywqUSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/eager\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Читай на TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/ru/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Запусти в Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/ru/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Изучай код на GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "EGjDcGxIqEfX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Eager execution в TensorFlow - это окружение императивного программирования, в котором все операции выполняются сразу же, без построения графов: операции возвращают конкретные значения вместо создания вычислительных графов. Это позволяет легко запускать любой код в TensorFlow, упрощает отладку моделей и устраняет надобность в шаблонном boilerplate коде. Чтобы следовать по этапам в этом руководстве просто запускай примеры кода в интерпретаторе `python` ниже.\n",
        "\n",
        "Eager execution является гибкой платформой машинного обучения для проведения\n",
        "исследований и экспериментов. Ее основные преимущества:\n",
        "\n",
        "* *Интуитивный интерфейс* — структурируй свой код и используй стандартные структуры \n",
        "данных Python. Быстро проверяй гипотезы с помощью небольших моделей на малых данных\n",
        "* *Легкая отладка кода* — Производи любые операции непосредственно на готовых \n",
        "моделях и проверяй изменения. Используй стандартные инструменты для отладки \n",
        "Python кода для незамедлительного отчета об ошибках\n",
        "* *Естественный порядок выполнения* — Используй порядок выполнения Python вместо порядка графов, упрощая спецификацию динамических моделей\n",
        "\n",
        "Eager execution поддерживает большиноство операций TensoFlow и ускорение при помощи GPU.\n",
        "Смотри собрание основных примеров, которые можно\n",
        "запускать в eager execution здесь:\n",
        "[Примеры в Eager Execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples).\n",
        "\n",
        "Обрати внимание: некоторые модели могут испытывать повышенную\n",
        "нагрузку при включенном eager execution. Улучшения эффективности\n",
        "этой функции находятся в непрерывной разработке, пожалуйста\n",
        "[сообщайте о багах](https://github.com/tensorflow/tensorflow/issues) если\n",
        "сталкиваетесь с какими-либо проблемами."
      ]
    },
    {
      "metadata": {
        "id": "RBAeIwOMrYk8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Установка и использование\n"
      ]
    },
    {
      "metadata": {
        "id": "48P3-8q4qEfe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы запустить eager execution, добавь `tf.enable_eager_execution()` в начало\n",
        "программы или консольной сессии. Не добавляй эту операцию к другим модулям,\n",
        "которые вызывает программа."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "7aFsD8csqEff",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_G1zZT5qEfh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь ты можешь запускать любые операции TensorFlow и получать результаты мгновенно:"
      ]
    },
    {
      "metadata": {
        "id": "5hien2IEqwLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.executing_eagerly() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "9gsI54pbqEfj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajFn6qsdqEfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Включение режима eager execution изменяет то, как себя ведут операции TensorFlow:\n",
        "теперь они вычисляются мгновенно. Объекты `tf.Tensor` относятся к конкретным\n",
        "значениям вместо символических имен вычислительных графов. Так как теперь\n",
        "нет вычислиельного графа, который нужно построить и затем запустить в сессии,\n",
        "можно легко инспектировать результаты при помощи функции `print()`\n",
        "или отладчика. Вычисление, вывод данных и проверка значений тензоров\n",
        "не нарушает порядок выполнения для расчета градиентов.\n",
        "\n",
        "Eager execution легко работает с [NumPy](http://www.numpy.org/). Операции NumPy\n",
        "принимают аргументы `tf.Tensor`. [Математические операции](https://www.tensorflow.org/api_guides/python/math_ops) TensorFlow конвертируют\n",
        "объекты Python и массивы NumPy в объекты `tf.Tensor`. Метод\n",
        "`tf.Tensor.numpy` возвращает значение объекта как массив NumPy `ndarray`."
      ]
    },
    {
      "metadata": {
        "id": "sTO0_5TYqz1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dp14YT8Gq4r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Проверям при помощи функции `print`\n",
        "b = tf.add(a, 1)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69p3waMfq8cQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Поддерживается перегрузка операторов\n",
        "print(a * b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "Ui025t1qqEfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Используем значения NumPy\n",
        "import numpy as np\n",
        "\n",
        "c = np.multiply(a, b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tq_aFRzWrCua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Получаем значение NumPy из тензора:\n",
        "print(a.numpy())\n",
        "# => [[1 2]\n",
        "#     [3 4]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jdg3nZFwqEfp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Модуль `tf.contrib.eager` содержит символы, доступные как в eager, так и в стандартном окружении graph execution, и является весьма полезным при [работе с графами](#work_with_graphs):"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "N-2lSGiHqEfq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfe = tf.contrib.eager"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H08f9ss9qEft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Динамический порядок выполнения\n",
        "\n",
        "Большим преимуществом eager execution является то, что весь\n",
        "функционал языка host доступен в то время, как запущена модель.\n",
        "Например, можно легко написать решение задачи [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz):"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "0fudRMeUqEfu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fizzbuzz(max_num):\n",
        "  counter = tf.constant(0)\n",
        "  max_num = tf.convert_to_tensor(max_num)\n",
        "  for num in range(1, max_num.numpy()+1):\n",
        "    num = tf.constant(num)\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num.numpy())\n",
        "    counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2cKknQWrJLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kA-aC3BqEfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Есть условные операторы, которые зависят от значений тензоров, и эти\n",
        "значения выводятся в среде выполнения нашей программы."
      ]
    },
    {
      "metadata": {
        "id": "zn3mp-j6rjnk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Построение модели\n",
        "\n",
        "Многие модели машинного обучения состоят из сочетания слоев. Когда\n",
        "мы используем TensorFlow с eager execution, ты можешь либо создавать\n",
        "свои собственные слои или использовать уже готовые, которые\n",
        "определеные в `tf.keras.layers`.\n",
        "\n",
        "В то время как ты можешь использовать любой объект Python для\n",
        "представления слоя, в TensorFlow есть удобный способ использования\n",
        "базовых классов слоев из `tf.keras.layers.Layers`. Используй их\n",
        "для создания своего собственного слоя:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "kvXiJsmyqEfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MySimpleLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_units):\n",
        "    super(MySimpleLayer, self).__init__()\n",
        "    self.output_units = output_units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # Метод `build` вызывается первый раз, когда используется слой.\n",
        "    # Создание переменных на build() позволяет тебе сделать их форму\n",
        "    # зависимой от входной формы и таким образом устранить необходимость\n",
        "    # пользователю уточнять формы полностью. Также возможно создавать переменные\n",
        "    # во время __init__() если ты уже знаешь их полные формы\n",
        "    self.kernel = self.add_variable(\n",
        "      \"kernel\", [input_shape[-1], self.output_units])\n",
        "\n",
        "  def call(self, input):\n",
        "    # Перепишем call() вместо __call__ чтобы мы могли вести счет\n",
        "    return tf.matmul(input, self.kernel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eo3qgrVCqEf2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Используй слой `tf.keras.layers.Dense` вместо `MySimpleLayer` выше так как\n",
        "он включает в себя надмножество (также может включить смещение `bias`).\n",
        "\n",
        "Когда составляешь слои в модели ты можешь использовать `tf.keras.Sequential` для\n",
        "представления моделей, которые являются линейный стеком слоев. Это легко использовать\n",
        "для стандартных моделей:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "VrfLnhNPqEf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=(784,)),  # нужно указать входящую форму\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dms3mduTqEf6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Альтернативный способ - организовать модели в классы из `tf.keras.Model`.\n",
        "Это контейнер слоев, который также сам является  слоем, что позволяет\n",
        "объектам `tf.keras.Model` содержать в себе другие объекты `tf.keras.Model`."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "MwWxQmNOqEf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MNISTModel, self).__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(units=10)\n",
        "    self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "  def call(self, input):\n",
        "    \"\"\"Run the model.\"\"\"\n",
        "    result = self.dense1(input)\n",
        "    result = self.dense2(result)\n",
        "    result = self.dense2(result)  # повторно используем переменные из слоя dense2\n",
        "    return result\n",
        "\n",
        "model = MNISTModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a639YaF4qEf-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Необязательно устанавливать входящую форм для классов `tf.keras.Model`,\n",
        "поскольку параметры устанавливаются первый раз и передаются слою.\n",
        "\n",
        "Классы `tf.keras.layers` создают и содержат собственные переменные\n",
        "моделей, время действия которых привязаны к объектам слоев. Чтобы разделить\n",
        "переменные слоев, необходимо разделить их объекты."
      ]
    },
    {
      "metadata": {
        "id": "8huKpuuAwICq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Обучение в Eager"
      ]
    },
    {
      "metadata": {
        "id": "mp2lCCZYrxHd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Вычисление градиентов\n",
        "\n",
        "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "is useful for implementing machine learning algorithms such as\n",
        "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation) for training\n",
        "neural networks. During eager execution, use `tf.GradientTape` to trace\n",
        "operations for computing gradients later.\n",
        "\n",
        "`tf.GradientTape` is an opt-in feature to provide maximal performance when\n",
        "not tracing. Since different operations can occur during each call, all\n",
        "forward-pass operations get recorded to a \"tape\". To compute the gradient, play\n",
        "the tape backwards and then discard. A particular `tf.GradientTape` can only\n",
        "compute one gradient; subsequent calls throw a runtime error."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "7g1yWiSXqEf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkHs32GqweYS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Обучение модели\n",
        "\n",
        "The following example creates a multi-layer model that classifies the standard\n",
        "MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build\n",
        "trainable graphs in an eager execution environment."
      ]
    },
    {
      "metadata": {
        "id": "38kymXZowhhz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Загружаем и форматируем данные mnist\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
        "   tf.cast(mnist_labels,tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rl1K8rOowmwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Создаем модель\n",
        "mnist_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fvyk-HgGwxwl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Even without training, call the model and inspect the output in eager execution:"
      ]
    },
    {
      "metadata": {
        "id": "BsxystjBwxLS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for images,labels in dataset.take(1):\n",
        "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3PGa8G7qEgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While keras models have a builtin training loop (using the `fit` method), sometimes you need more customization. Here's an example, of a training loop implemented with eager:"
      ]
    },
    {
      "metadata": {
        "id": "bzRhM7JDnaEG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "loss_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "0m1xAXrmqEgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for (batch, (images, labels)) in enumerate(dataset.take(400)):\n",
        "  if batch % 80 == 0:\n",
        "    print()\n",
        "  print('.', end='')\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = mnist_model(images, training=True)\n",
        "    loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "\n",
        "  loss_history.append(loss_value.numpy())\n",
        "  grads = tape.gradient(loss_value, mnist_model.variables)\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.variables),\n",
        "                            global_step=tf.train.get_or_create_global_step())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vG5ql_2vYB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Батч #')\n",
        "plt.ylabel('Потери [энтропия]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ODzXW8xqEgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example uses the\n",
        "[dataset.py module](https://github.com/tensorflow/models/blob/master/official/mnist/dataset.py)\n",
        "from the\n",
        "[TensorFlow MNIST example](https://github.com/tensorflow/models/tree/master/official/mnist);\n",
        "download this file to your local directory. Run the following to download the\n",
        "MNIST data files to your working directory and prepare a `tf.data.Dataset`\n",
        "for training:"
      ]
    },
    {
      "metadata": {
        "id": "kKpOlHPLqEgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Variables and optimizers\n",
        "\n",
        "`tf.Variable` objects store mutable `tf.Tensor` values accessed during\n",
        "training to make automatic differentiation easier. The parameters of a model can\n",
        "be encapsulated in classes as variables.\n",
        "\n",
        "Better encapsulate model parameters by using `tf.Variable` with\n",
        "`tf.GradientTape`. For example, the automatic differentiation example above\n",
        "can be rewritten:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "nnQLBYmEqEgm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.W = tf.Variable(5., name='weight')\n",
        "    self.B = tf.Variable(10., name='bias')\n",
        "  def call(self, inputs):\n",
        "    return inputs * self.W + self.B\n",
        "\n",
        "# A toy dataset of points around 3 * x + 2\n",
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
        "noise = tf.random_normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "\n",
        "# The loss function to be optimized\n",
        "def loss(model, inputs, targets):\n",
        "  error = model(inputs) - targets\n",
        "  return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return tape.gradient(loss_value, [model.W, model.B])\n",
        "\n",
        "# Define:\n",
        "# 1. A model.\n",
        "# 2. Derivatives of a loss function with respect to model parameters.\n",
        "# 3. A strategy for updating the variables based on the derivatives.\n",
        "model = Model()\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "# Training loop\n",
        "for i in range(300):\n",
        "  grads = grad(model, training_inputs, training_outputs)\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n",
        "                            global_step=tf.train.get_or_create_global_step())\n",
        "  if i % 20 == 0:\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPjb8nRWqEgr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use objects for state during eager execution\n",
        "\n",
        "With graph execution, program state (such as the variables) is stored in global\n",
        "collections and their lifetime is managed by the `tf.Session` object. In\n",
        "contrast, during eager execution the lifetime of state objects is determined by\n",
        "the lifetime of their corresponding Python object.\n",
        "\n",
        "### Variables are objects\n",
        "\n",
        "During eager execution, variables persist until the last reference to the object\n",
        "is removed, and is then deleted."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "A2boS674qEgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  with tf.device(\"gpu:0\"):\n",
        "    v = tf.Variable(tf.random_normal([1000, 1000]))\n",
        "    v = None  # v no longer takes up GPU memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scMjg6L6qEgv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Object-based saving\n",
        "\n",
        "`tf.train.Checkpoint` can save and restore `tf.Variable`s to and from\n",
        "checkpoints:"
      ]
    },
    {
      "metadata": {
        "id": "7z5xRfdHzZOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.Variable(10.)\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IffrUVG7zyVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.assign(2.)   # Assign a new value to the variables and save.\n",
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save('./ckpt/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "eMT9koCoqEgw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.assign(11.)  # Change the variable after saving.\n",
        "\n",
        "# Restore values from the checkpoint\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "print(x)  # => 2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbFnP-yLqEgx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To save and load models, `tf.train.Checkpoint` stores the internal state of objects,\n",
        "without requiring hidden variables. To record the state of a `model`,\n",
        "an `optimizer`, and a global step, pass them to a `tf.train.Checkpoint`:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "hWZHyAXMqEg0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "checkpoint_dir = '/path/to/model_dir'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                           model=model,\n",
        "                           optimizer_step=tf.train.get_or_create_global_step())\n",
        "\n",
        "root.save(checkpoint_prefix)\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yoD0VJ7qEg3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Object-oriented metrics\n",
        "\n",
        "`tfe.metrics` are stored as objects. Update a metric by passing the new data to\n",
        "the callable, and retrieve the result using the `tfe.metrics.result` method,\n",
        "for example:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "9ccu0iAaqEg5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = tfe.metrics.Mean(\"loss\")\n",
        "m(0)\n",
        "m(5)\n",
        "m.result()  # => 2.5\n",
        "m([8, 9])\n",
        "m.result()  # => 5.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BE8cXErYqEg8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Summaries and TensorBoard\n",
        "\n",
        "[TensorBoard](../guide/summaries_and_tensorboard.md) is a visualization tool for\n",
        "understanding, debugging and optimizing the model training process. It uses\n",
        "summary events that are written while executing the program.\n",
        "\n",
        "`tf.contrib.summary` is compatible with both eager and graph execution\n",
        "environments. Summary operations, such as `tf.contrib.summary.scalar`, are\n",
        "inserted during model construction. For example, to record summaries once every\n",
        "100 global steps:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "3PXAJB1GqEg9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "logdir = \"./tb/\"\n",
        "writer = tf.contrib.summary.create_file_writer(logdir)\n",
        "writer.set_as_default()\n",
        "\n",
        "for _ in range(10):\n",
        "  global_step.assign_add(1)\n",
        "  # Must include a record_summaries method\n",
        "  with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
        "    # your model code goes here\n",
        "    tf.contrib.summary.scalar('global_step', global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TJSs_wG8Spg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls tb/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xEL4yJe5qEhD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Advanced automatic differentiation topics\n",
        "\n",
        "### Dynamic models\n",
        "\n",
        "`tf.GradientTape` can also be used in dynamic models. This example for a\n",
        "[backtracking line search](https://wikipedia.org/wiki/Backtracking_line_search)\n",
        "algorithm looks like normal NumPy code, except there are gradients and is\n",
        "differentiable, despite the complex control flow:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "L518n5dkqEhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Variables are automatically recorded, but manually watch a tensor\n",
        "    tape.watch(init_x)\n",
        "    value = fn(init_x)\n",
        "  grad = tape.gradient(value, init_x)\n",
        "  grad_norm = tf.reduce_sum(grad * grad)\n",
        "  init_value = value\n",
        "  while value > init_value - rate * grad_norm:\n",
        "    x = init_x - rate * grad\n",
        "    value = fn(x)\n",
        "    rate /= 2.0\n",
        "  return x, value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "03owpCFrqEhH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Additional functions to compute gradients\n",
        "\n",
        "`tf.GradientTape` is a powerful interface for computing gradients, but there\n",
        "is another [Autograd](https://github.com/HIPS/autograd)-style API available for\n",
        "automatic differentiation. These functions are useful if writing math code with\n",
        "only tensors and gradient functions, and without `tf.Variables`:\n",
        "\n",
        "* `tfe.gradients_function` —Returns a function that computes the derivatives\n",
        "  of its input function parameter with respect to its arguments. The input\n",
        "  function parameter must return a scalar value. When the returned function is\n",
        "  invoked, it returns a list of `tf.Tensor` objects: one element for each\n",
        "  argument of the input function. Since anything of interest must be passed as a\n",
        "  function parameter, this becomes unwieldy if there's a dependency on many\n",
        "  trainable parameters.\n",
        "* `tfe.value_and_gradients_function` —Similar to\n",
        "  `tfe.gradients_function`, but when the returned function is invoked, it\n",
        "  returns the value from the input function in addition to the list of\n",
        "  derivatives of the input function with respect to its arguments.\n",
        "\n",
        "In the following example, `tfe.gradients_function` takes the `square`\n",
        "function as an argument and returns a function that computes the partial\n",
        "derivatives of `square` with respect to its inputs. To calculate the derivative\n",
        "of `square` at `3`, `grad(3.0)` returns `6`."
      ]
    },
    {
      "metadata": {
        "id": "QDPFUG-68i-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def square(x):\n",
        "  return tf.multiply(x, x)\n",
        "\n",
        "grad = tfe.gradients_function(square)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Ow9LHre8k_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "square(3.).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rg5ea0kC8nEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grad(3.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41D1LzcG87p8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The second-order derivative of square:\n",
        "gradgrad = tfe.gradients_function(lambda x: grad(x)[0])\n",
        "gradgrad(3.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "DotEGcx5qEhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The third-order derivative is None:\n",
        "gradgradgrad = tfe.gradients_function(lambda x: gradgrad(x)[0])\n",
        "gradgradgrad(3.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9DRAews99F4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# With flow control:\n",
        "def abs(x):\n",
        "  return x if x > 0. else -x\n",
        "\n",
        "grad = tfe.gradients_function(abs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTA1jmu_9gyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grad(3.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7zs8JpKw9kir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grad(-3.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gieGOf_DqEhK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom gradients\n",
        "\n",
        "Custom gradients are an easy way to override gradients in eager and graph\n",
        "execution. Within the forward function, define the gradient with respect to the\n",
        "inputs, outputs, or intermediate results. For example, here's an easy way to clip\n",
        "the norm of the gradients in the backward pass:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "-OwwsWUAqEhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x, norm):\n",
        "  y = tf.identity(x)\n",
        "  def grad_fn(dresult):\n",
        "    return [tf.clip_by_norm(dresult, norm), None]\n",
        "  return y, grad_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPLDHkF_qEhN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Custom gradients are commonly used to provide a numerically stable gradient for a\n",
        "sequence of operations:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "24WiLROnqEhO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log1pexp(x):\n",
        "  return tf.log(1 + tf.exp(x))\n",
        "grad_log1pexp = tfe.gradients_function(log1pexp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8fq69r9-B-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The gradient computation works fine at x = 0.\n",
        "grad_log1pexp(0.)[0].numpy() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VFSU0mG-FSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# However, x = 100 fails because of numerical instability.\n",
        "grad_log1pexp(100.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-VcTR34rqEhQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, the `log1pexp` function can be analytically simplified with a custom\n",
        "gradient. The implementation below reuses the value for `tf.exp(x)` that is\n",
        "computed during the forward pass—making it more efficient by eliminating\n",
        "redundant calculations:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "Q7nvfx_-qEhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def log1pexp(x):\n",
        "  e = tf.exp(x)\n",
        "  def grad(dy):\n",
        "    return dy * (1 - 1 / (1 + e))\n",
        "  return tf.log(1 + e), grad\n",
        "\n",
        "grad_log1pexp = tfe.gradients_function(log1pexp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gHPKMfl-Kge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As before, the gradient computation works fine at x = 0.\n",
        "grad_log1pexp(0.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u38MOfz3-MDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# And the gradient computation also works at x = 100.\n",
        "grad_log1pexp(100.)[0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnZXjfQzqEhV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Performance\n",
        "\n",
        "Computation is automatically offloaded to GPUs during eager execution. If you\n",
        "want control over where a computation runs you can enclose it in a\n",
        "`tf.device('/gpu:0')` block (or the CPU equivalent):"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "Ac9Y64H-qEhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure(x, steps):\n",
        "  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
        "  tf.matmul(x, x)\n",
        "  start = time.time()\n",
        "  for i in range(steps):\n",
        "    x = tf.matmul(x, x)\n",
        "  # tf.matmul can return before completing the matrix multiplication\n",
        "  # (e.g., can return after enqueing the operation on a CUDA stream).\n",
        "  # The x.numpy() call below will ensure that all enqueued operations\n",
        "  # have completed (and will also copy the result to host memory,\n",
        "  # so we're including a little more than just the matmul operation\n",
        "  # time).\n",
        "  _ = x.numpy()\n",
        "  end = time.time()\n",
        "  return end - start\n",
        "\n",
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
        "\n",
        "# Run on CPU:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "  print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
        "\n",
        "# Run on GPU, if available:\n",
        "if tfe.num_gpus() > 0:\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
        "else:\n",
        "  print(\"GPU: not found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLw3IS7UqEhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A `tf.Tensor` object can be copied to a different device to execute its\n",
        "operations:"
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "ny6LX2BVqEhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  x = tf.random_normal([10, 10])\n",
        "\n",
        "  x_gpu0 = x.gpu()\n",
        "  x_cpu = x.cpu()\n",
        "\n",
        "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n",
        "\n",
        "  if tfe.num_gpus() > 1:\n",
        "    x_gpu1 = x.gpu(1)\n",
        "    _ = tf.matmul(x_gpu1, x_gpu1)  # Runs on GPU:1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oA_qaII3-p6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Benchmarks\n",
        "\n",
        "For compute-heavy models, such as\n",
        "[ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)\n",
        "training on a GPU, eager execution performance is comparable to graph execution.\n",
        "But this gap grows larger for models with less computation and there is work to\n",
        "be done for optimizing hot code paths for models with lots of small operations."
      ]
    },
    {
      "metadata": {
        "id": "TjMTyFIp-sSE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Work with graphs\n",
        "\n",
        "While eager execution makes development and debugging more interactive,\n",
        "TensorFlow graph execution has advantages for distributed training, performance\n",
        "optimizations, and production deployment. However, writing graph code can feel\n",
        "different than writing regular Python code and more difficult to debug.\n",
        "\n",
        "For building and training graph-constructed models, the Python program first\n",
        "builds a graph representing the computation, then invokes `Session.run` to send\n",
        "the graph for execution on the C++-based runtime.  This provides:\n",
        "\n",
        "* Automatic differentiation using static autodiff.\n",
        "* Simple deployment to a platform independent server.\n",
        "* Graph-based optimizations (common subexpression elimination, constant-folding, etc.).\n",
        "* Compilation and kernel fusion.\n",
        "* Automatic distribution and replication (placing nodes on the distributed system).\n",
        "\n",
        "Deploying code written for eager execution is more difficult: either generate a\n",
        "graph from the model, or run the Python runtime and code directly on the server."
      ]
    },
    {
      "metadata": {
        "id": "hll3ZbE5qEhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Write compatible code\n",
        "\n",
        "The same code written for eager execution will also build a graph during graph\n",
        "execution. Do this by simply running the same code in a new Python session where\n",
        "eager execution is not enabled.\n",
        "\n",
        "Most TensorFlow operations work during eager execution, but there are some things\n",
        "to keep in mind:\n",
        "\n",
        "* Use `tf.data` for input processing instead of queues. It's faster and easier.\n",
        "* Use object-oriented layer APIs—like `tf.keras.layers` and\n",
        "  `tf.keras.Model`—since they have explicit storage for variables.\n",
        "* Most model code works the same during eager and graph execution, but there are\n",
        "  exceptions. (For example, dynamic models using Python control flow to change the\n",
        "  computation based on inputs.)\n",
        "* Once eager execution is enabled with `tf.enable_eager_execution`, it\n",
        "  cannot be turned off. Start a new Python session to return to graph execution.\n",
        "\n",
        "It's best to write code for both eager execution *and* graph execution. This\n",
        "gives you eager's interactive experimentation and debuggability with the\n",
        "distributed performance benefits of graph execution.\n",
        "\n",
        "Write, debug, and iterate in eager execution, then import the model graph for\n",
        "production deployment. Use `tf.train.Checkpoint` to save and restore model\n",
        "variables, this allows movement between eager and graph execution environments.\n",
        "See the examples in:\n",
        "[tensorflow/contrib/eager/python/examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sPoSUqmL-ts5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use eager execution in a graph environment\n",
        "\n",
        "Selectively enable eager execution in a TensorFlow graph environment using\n",
        "`tfe.py_func`. This is used when `tf.enable_eager_execution()` has *not*\n",
        "been called."
      ]
    },
    {
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "Lks-3LB0qEhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_py_func(x):\n",
        "  x = tf.matmul(x, x)  # You can use tf ops\n",
        "  print(x)  # but it's eager!\n",
        "  return x\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x = tf.placeholder(dtype=tf.float32)\n",
        "  # Call eager function in graph!\n",
        "  pf = tfe.py_func(my_py_func, [x], tf.float32)\n",
        "  \n",
        "  sess.run(pf, feed_dict={x: [[2.0]]})  # [[4.0]]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}