{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eager.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "kKpOlHPLqEgl",
        "rPjb8nRWqEgr"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "z6X9omPnfO_h",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2QQJJyDzqGRb"
      },
      "source": [
        "# Temas esenciales de la ejecución \"Eager\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dEQgTPa_TAd",
        "colab_type": "text"
      },
      "source": [
        "Nota: Nuestra comunidad de Tensorflow ha traducido estos documentos. Como las traducciones de la comunidad son basados en el \"mejor esfuerzo\", no hay ninguna garantia que esta sea un reflejo preciso y actual de la Documentacion Oficial en Ingles. Si tienen sugerencias sobre como mejorar esta traduccion, por favor envian un \"Pull request\" al siguiente repositorio tensorflow/docs. Para ofrecerse como voluntario o hacer revision de las traducciones de la Comunidad por favor contacten al siguiente grupo docs@tensorflow.org list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B1xdylywqUSX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/eager\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />Visualizar en TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver código fuente en GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Descargar notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EGjDcGxIqEfX"
      },
      "source": [
        "\n",
        "\"Eager\" es un entorno de programación imperativo que\n",
        "evalúa las operaciones de inmediato, sin construir grafos: las operaciones regresan\n",
        "valores concretos en lugar de construir un grafo computacional para ejecutar más tarde. Esto\n",
        "facilita comenzar con los modelos TensorFlow,depuración, y\n",
        "reduce el  codigo repetitivo. Para seguir esta guía, ejecute el código.\n",
        "ejemplos a continuación en un intérprete interactivo de `python`.\n",
        "\n",
        "La ejecución \"eager\" es una plataforma flexible de aprendizaje automático para la investigación y\n",
        "experimentación, proporcionando:\n",
        "\n",
        "* * Una interfaz intuitiva *: estructura tu código de forma natural y usa datos de Python\n",
        "  estructuras Repita rápidamente en modelos pequeños y datos pequeños.\n",
        "* * Depuración más fácil *: llame a las operaciones directamente para inspeccionar los modelos en ejecución y probar\n",
        "  cambios Utilice las herramientas de depuración de Python estándar para la generación de informes de errores inmediatos.\n",
        "* * Flujo de control natural *: utilice el flujo de control de Python en lugar del control de gráfico\n",
        "  flujo, simplificando la especificación de modelos dinámicos.\n",
        "\n",
        "La ejecución rápida admite la mayoría de las operaciones de TensorFlow y la aceleración de GPU.\n",
        "\n",
        "Nota: Algunos modelos pueden experimentar una sobrecarga mayor con una ejecución eager\n",
        "habilitado Las mejoras de rendimiento están en curso, pero por favor\n",
        "[presentar un error] (https://github.com/tensorflow/tensorflow/issues) si encuentra un\n",
        "problema y comparte tu solución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RBAeIwOMrYk8"
      },
      "source": [
        "## Preparación y uso básico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByNsp4VqqEfa",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version solo existe en Colab.\n",
        "  %tensorflow_version 2.x  #gpu\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import cProfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "48P3-8q4qEfe"
      },
      "source": [
        "En Tensorflow 2.0, la ejecución \"eager\" está habilitada por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "7aFsD8csqEff",
        "colab": {}
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x_G1zZT5qEfh"
      },
      "source": [
        "Ahora puedes ejecutar operaciones en TensorFlow y los resultados se ejecutarán inmediatamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "9gsI54pbqEfj",
        "colab": {}
      },
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ajFn6qsdqEfl"
      },
      "source": [
        "La habilitación de la ejecución \"eager\" cambia la forma en que se comportan las operaciones de TensorFlow; ahora evalúan de inmediato y devuelven sus valores a Python. los objetos hacen referencia a valores concretos en lugar de identificadores simbólicos a nodos en un grafo. Dado que no hay un grafo computacional para construir y ejecutar más tarde en una sesión, es fácil inspeccionar los resultados usando `print ()` o un depurador. Evaluar, imprimir y verificar los valores del tensor no interrumpe el flujo para calcular gradientes.\n",
        "\n",
        "La ejecución \"eager\" funciona bien con [NumPy](http://www.numpy.org/). Las operaciones de NumPy aceptan argumentos de `tf.Tensor`. Las [operaciones matemáticas](https://www.tensorflow.org/api_guides/python/math_ops) TensorFlow convierten los objetos Python y las matrices NumPy en objetos `tf.Tensor`. El método `tf.Tensor`. los métodos de numpy devuelven el valor del objeto como una matriz de datos (`ndarray`) NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTO0_5TYqz1n",
        "colab": {}
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dp14YT8Gq4r1",
        "colab": {}
      },
      "source": [
        "# Soporte de broadcasting\n",
        "b = tf.add(a, 1)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69p3waMfq8cQ",
        "colab": {}
      },
      "source": [
        "# La sobrecarga de operadores es compatible\n",
        "print(a * b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Ui025t1qqEfm",
        "colab": {}
      },
      "source": [
        "# Usar funciones de NumPy\n",
        "import numpy as np\n",
        "\n",
        "c = np.multiply(a, b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tq_aFRzWrCua",
        "colab": {}
      },
      "source": [
        "# Obtener valores numpy de un tensor:\n",
        "print(a.numpy())\n",
        "# => [[1 2]\n",
        "#     [3 4]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H08f9ss9qEft"
      },
      "source": [
        "## Flujo de control dinámico\n",
        "\n",
        "Una ventaja importante de la ejecución \"eager\" es que toda la funcionalidad del host el idioma está disponible mientras su modelo se está ejecutando. Así por ejemplo,\n",
        "es facil de escribir [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "0fudRMeUqEfu",
        "colab": {}
      },
      "source": [
        "def fizzbuzz(max_num):\n",
        "  counter = tf.constant(0)\n",
        "  max_num = tf.convert_to_tensor(max_num)\n",
        "  for num in range(1, max_num.numpy()+1):\n",
        "    num = tf.constant(num)\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "      print('FizzBuzz')\n",
        "    elif int(num % 3) == 0:\n",
        "      print('Fizz')\n",
        "    elif int(num % 5) == 0:\n",
        "      print('Buzz')\n",
        "    else:\n",
        "      print(num.numpy())\n",
        "    counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P2cKknQWrJLB",
        "colab": {}
      },
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7kA-aC3BqEfy"
      },
      "source": [
        "Esto tiene condicionales que dependen de los valores del tensor e imprime estos valores en tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8huKpuuAwICq"
      },
      "source": [
        "## Ejercicios utilizando ejercución Eager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mp2lCCZYrxHd"
      },
      "source": [
        "### Computación de gradientes\n",
        "\n",
        "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "es útil para implementar con algoritmos de aprendizaje automático como\n",
        "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation) para entrenar redes neuronales. Durante la ejecución eager, usa `tf.GradientTape` para rastrear operaciones y calcular gradientes más tarde.\n",
        "\n",
        "Puede usar `tf.GradientTape` para entrenar y / o calcular gradientes con eager. Es especialmente útil para bucles complicados de entrenamiento.\n",
        "\n",
        "Since different operations can occur during each call, all\n",
        "forward-pass operations get recorded to a \"tape\". To compute the gradient, play\n",
        "the tape backwards and then discard. A particular `tf.GradientTape` can only\n",
        "compute one gradient; subsequent calls throw a runtime error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "7g1yWiSXqEf-",
        "colab": {}
      },
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkHs32GqweYS"
      },
      "source": [
        "### Entrenar un modelo\n",
        "\n",
        "El siguiente ejemplo crea un modelo de varias capas que clasifica los dígitos manuscritos MNIST estándar. Demuestra el optimizador y las API de capa para crear grafos entrenables en un entorno de ejecución ansioso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38kymXZowhhz",
        "colab": {}
      },
      "source": [
        "# Obtener y dar forma a los datos mnist\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
        "   tf.cast(mnist_labels,tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rl1K8rOowmwT",
        "colab": {}
      },
      "source": [
        "# Construir el modelo\n",
        "mnist_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
        "                         input_shape=(None, None, 1)),\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fvyk-HgGwxwl"
      },
      "source": [
        "\n",
        "Even without training, call the model and inspect the output in eager execution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BsxystjBwxLS",
        "colab": {}
      },
      "source": [
        "for images,labels in dataset.take(1):\n",
        "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3PGa8G7qEgB"
      },
      "source": [
        "While keras models have a builtin training loop (using the `fit` method), sometimes you need more customization. Here's an example, of a training loop implemented with eager:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzRhM7JDnaEG",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "loss_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tXaupYXRI2YM"
      },
      "source": [
        "Note: Use the assert functions in `tf.debugging` to check if a condition holds up. This works in eager and graph execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DDHrigtiCIA4",
        "colab": {}
      },
      "source": [
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = mnist_model(images, training=True)\n",
        "    \n",
        "    # Agregar \"asserts\" para verificar la forma de la salida.\n",
        "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
        "    \n",
        "    loss_value = loss_object(labels, logits)\n",
        "\n",
        "  loss_history.append(loss_value.numpy().mean())\n",
        "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "0m1xAXrmqEgJ",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  for epoch in range(3):\n",
        "    for (batch, (images, labels)) in enumerate(dataset):\n",
        "      train_step(images, labels)\n",
        "    print ('Epoch {} finished'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5dGz0p_nf4W",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5vG5ql_2vYB5",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('Loss [entropy]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKpOlHPLqEgl"
      },
      "source": [
        "### Variables y optimizadores\n",
        "\n",
        "Los objetos `tf.Variable` almacenan valores mutables de` tf.Tensor` a los que se accede durante capacitación para facilitar la diferenciación automática. Los parámetros de un modelo pueden ser encapsulado en clases como variables.\n",
        "\n",
        "Es mejor encapsular los parámetros del modelo utilizando `tf.Variable` con\n",
        "`tf.GradientTape`. Por ejemplo, el ejemplo de diferenciación automática anterior\n",
        "puede reescribirse:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "nnQLBYmEqEgm",
        "colab": {}
      },
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.W = tf.Variable(5., name='weight')\n",
        "    self.B = tf.Variable(10., name='bias')\n",
        "  def call(self, inputs):\n",
        "    return inputs * self.W + self.B\n",
        "\n",
        "# Un conjunto de datos de puntos alrededor 3 * x + 2\n",
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "\n",
        "# La función de pérdida a optimizar\n",
        "def loss(model, inputs, targets):\n",
        "  error = model(inputs) - targets\n",
        "  return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return tape.gradient(loss_value, [model.W, model.B])\n",
        "\n",
        "# Definir:\n",
        "# 1. Un modelo.\n",
        "# 2. Derivadas de una función de pérdida con respecto a los parámetros del modelo.\n",
        "# 3. Una estrategia para actualizar las variables basadas en las derivadas.\n",
        "model = Model()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "# Loop de entrenamiento\n",
        "for i in range(300):\n",
        "  grads = grad(model, training_inputs, training_outputs)\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
        "  if i % 20 == 0:\n",
        "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rPjb8nRWqEgr"
      },
      "source": [
        "## Use objetos para el estado durante la ejecución eager\n",
        "\n",
        "Con la ejecución del grafo TF 1.x, el estado del programa (como las variables) se almacena en colecciones globales y su vida útil es administrada por el objeto `tf.Session`. Por el contrario, durante la ejecución ansiosa, la vida útil de los objetos de estado está determinada por la vida útil de su objeto Python correspondiente.\n",
        "\n",
        "\n",
        "### Las variables son objetos\n",
        "\n",
        "Durante la ejecución \"eager\", las variables persisten hasta que se elimina la última referencia al objeto y luego se elimina."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "A2boS674qEgs",
        "colab": {}
      },
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"gpu:0\"):\n",
        "    print(\"GPU enabled\")\n",
        "    v = tf.Variable(tf.random.normal([1000, 1000]))\n",
        "    v = None  # v ya no ocupa memoria de la GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "scMjg6L6qEgv"
      },
      "source": [
        "### Object-based saving\n",
        "\n",
        "This section is an abbreviated version of the [guide to training checkpoints](./checkpoints.ipynb).\n",
        "\n",
        "`tf.train.Checkpoint` can save and restore `tf.Variable`s to and from\n",
        "checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7z5xRfdHzZOQ",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(10.)\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IffrUVG7zyVb",
        "colab": {}
      },
      "source": [
        "x.assign(2.)   # Assign a new value to the variables and save.\n",
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save('./ckpt/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "eMT9koCoqEgw",
        "colab": {}
      },
      "source": [
        "x.assign(11.)  # Change the variable after saving.\n",
        "\n",
        "# Restore values from the checkpoint\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "print(x)  # => 2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vbFnP-yLqEgx"
      },
      "source": [
        "To save and load models, `tf.train.Checkpoint` stores the internal state of objects,\n",
        "without requiring hidden variables. To record the state of a `model`,\n",
        "an `optimizer`, and a global step, pass them to a `tf.train.Checkpoint`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "hWZHyAXMqEg0",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_dir = 'path/to/model_dir'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.makedirs(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                           model=model)\n",
        "\n",
        "root.save(checkpoint_prefix)\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-ITwkBCF6GJ"
      },
      "source": [
        "Note: In many training loops, variables are created after `tf.train.Checkpoint.restore` is called. These variables will be restored as soon as they are created, and assertions are available to ensure that a checkpoint has been fully loaded. See the [guide to training checkpoints](./checkpoints.ipynb) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3yoD0VJ7qEg3"
      },
      "source": [
        "### Object-oriented metrics\n",
        "\n",
        "`tf.keras.metrics` are stored as objects. Update a metric by passing the new data to\n",
        "the callable, and retrieve the result using the `tf.keras.metrics.result` method,\n",
        "for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "9ccu0iAaqEg5",
        "colab": {}
      },
      "source": [
        "m = tf.keras.metrics.Mean(\"loss\")\n",
        "m(0)\n",
        "m(5)\n",
        "m.result()  # => 2.5\n",
        "m([8, 9])\n",
        "m.result()  # => 5.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEL4yJe5qEhD"
      },
      "source": [
        "## Temas avanzados de diferenciación automática\n",
        "\n",
        "### Modelos dinámicos\n",
        "\n",
        "`tf.GradientTape` También se puede utilizar en modelos dinámicos. Este ejemplo para un\n",
        "[backtracking line search](https://wikipedia.org/wiki/Backtracking_line_search)\n",
        "El algoritmo se parece al código normal de NumPy, excepto que hay gradientes y es diferenciable, a pesar del flujo de control complejo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "L518n5dkqEhE",
        "colab": {}
      },
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Las variables se registran automáticamente, pero observan manualmente un tensor\n",
        "    tape.watch(init_x)\n",
        "    value = fn(init_x)\n",
        "  grad = tape.gradient(value, init_x)\n",
        "  grad_norm = tf.reduce_sum(grad * grad)\n",
        "  init_value = value\n",
        "  while value > init_value - rate * grad_norm:\n",
        "    x = init_x - rate * grad\n",
        "    value = fn(x)\n",
        "    rate /= 2.0\n",
        "  return x, value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gieGOf_DqEhK"
      },
      "source": [
        "### Gradientes personalizados\n",
        "\n",
        "Los degradados personalizados son una manera fácil de anular los degradados. Dentro de la función de avance, defina el gradiente con respecto a las entradas, salidas o resultados intermedios. Por ejemplo, aquí hay una manera fácil de recortar la norma de los gradientes en el paso hacia atrás:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "-OwwsWUAqEhK",
        "colab": {}
      },
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x, norm):\n",
        "  y = tf.identity(x)\n",
        "  def grad_fn(dresult):\n",
        "    return [tf.clip_by_norm(dresult, norm), None]\n",
        "  return y, grad_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPLDHkF_qEhN"
      },
      "source": [
        "Los gradientes personalizados se usan comúnmente para proporcionar un gradiente numéricamente estable para un secuencia de operaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "24WiLROnqEhO",
        "colab": {}
      },
      "source": [
        "def log1pexp(x):\n",
        "  return tf.math.log(1 + tf.exp(x))\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8fq69r9-B-c",
        "colab": {}
      },
      "source": [
        "# El cálculo de gradiente funciona bien en x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VFSU0mG-FSp",
        "colab": {}
      },
      "source": [
        "# Sin embargo, x = 100 falla debido a la inestabilidad numérica.\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-VcTR34rqEhQ"
      },
      "source": [
        "Aquí, la función `log1pexp` se puede simplificar analíticamente con un gradiente personalizado. La siguiente implementación reutiliza el valor de `tf.exp (x)` que se calcula durante el paso directo, lo que lo hace más eficiente al eliminar los cálculos redundantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Q7nvfx_-qEhS",
        "colab": {}
      },
      "source": [
        "@tf.custom_gradient\n",
        "def log1pexp(x):\n",
        "  e = tf.exp(x)\n",
        "  def grad(dy):\n",
        "    return dy * (1 - 1 / (1 + e))\n",
        "  return tf.math.log(1 + e), grad\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    value = log1pexp(x)\n",
        "  return tape.gradient(value, x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gHPKMfl-Kge",
        "colab": {}
      },
      "source": [
        "# Como antes, el cálculo de gradiente funciona bien en x = 0.\n",
        "grad_log1pexp(tf.constant(0.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u38MOfz3-MDE",
        "colab": {}
      },
      "source": [
        "# Y el cálculo de gradiente también funciona en x = 100.\n",
        "grad_log1pexp(tf.constant(100.)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rnZXjfQzqEhV"
      },
      "source": [
        "## Performance\n",
        "\n",
        "La computación se descarga automáticamente a las GPU durante la ejecución ansiosa. Si desea controlar dónde se ejecuta un cálculo, puede encerrarlo en un bloque `tf.device ('/ gpu: 0')` (o el equivalente de la CPU):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "Ac9Y64H-qEhX",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def measure(x, steps):\n",
        "  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
        "  tf.matmul(x, x)\n",
        "  start = time.time()\n",
        "  for i in range(steps):\n",
        "    x = tf.matmul(x, x)\n",
        "  # tf.matmul can return before completing the matrix multiplication\n",
        "  # (e.g., can return after enqueing the operation on a CUDA stream).\n",
        "  # The x.numpy() call below will ensure that all enqueued operations\n",
        "  # have completed (and will also copy the result to host memory,\n",
        "  # so we're including a little more than just the matmul operation\n",
        "  # time).\n",
        "  _ = x.numpy()\n",
        "  end = time.time()\n",
        "  return end - start\n",
        "\n",
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
        "\n",
        "# Run on CPU:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "  print(\"CPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "\n",
        "# Run on GPU, if available:\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    print(\"GPU: {} secs\".format(measure(tf.random.normal(shape), steps)))\n",
        "else:\n",
        "  print(\"GPU: not found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLw3IS7UqEhe"
      },
      "source": [
        "A `tf.Tensor` object can be copied to a different device to execute its\n",
        "operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "colab_type": "code",
        "id": "ny6LX2BVqEhf",
        "colab": {}
      },
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  x = tf.random.normal([10, 10])\n",
        "\n",
        "  x_gpu0 = x.gpu()\n",
        "  x_cpu = x.cpu()\n",
        "\n",
        "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oA_qaII3-p6c"
      },
      "source": [
        "### Benchmarks\n",
        "\n",
        "Para modelos pesados en cómputo, como\n",
        "[ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)\n",
        "entrenamiento en una GPU, el rendimiento de ejecución ansioso es comparable a la ejecución `tf.function`. Pero esta brecha se hace más grande para los modelos con menos cómputo y hay trabajo por hacer para optimizar las rutas de código activo para los modelos con muchas operaciones pequeñas.\n",
        "\n",
        "## Trabajar con funciones\n",
        "\n",
        "Si bien la ejecución eager hace que el desarrollo y la depuración sean más interactivos, la ejecución de gráficos de estilo TensorFlow 1.x tiene ventajas para la capacitación distribuida, las optimizaciones de rendimiento y la implementación de producción. Para cerrar esta brecha, TensorFlow 2.0 introduce `function`s a través de la API` tf.function`. Para más información, vea la guía de [Autograph](./autograph.ipynb)."
      ]
    }
  ]
}