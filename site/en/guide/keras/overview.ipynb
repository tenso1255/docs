{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "z6X9omPnfO_h"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1xIRPtY0E1w"
      },
      "source": [
        "# Keras overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VyOjQZHhZxaA"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/overview\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/overview.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VUJTep_x5-R8"
      },
      "source": [
        "This guide gives you the basics to get started with Keras. It's a 10-minute read."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IsK5aF2xZ-40"
      },
      "source": [
        "## Import tf.keras\n",
        "\n",
        "`tf.keras` is TensorFlow's implementation of the\n",
        "[Keras API specification](https://keras.io). This is a high-level\n",
        "API to build and train models that includes first-class support for\n",
        "TensorFlow-specific functionality, such as [eager execution](../eager.ipynb),\n",
        "`tf.data` pipelines, and [Estimators](../estimator.ipynb).\n",
        "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
        "performance.\n",
        "\n",
        "To get started, import `tf.keras` as part of your TensorFlow program setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TgPcBFru0E1z"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lj03RamP0E13"
      },
      "source": [
        "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
        "\n",
        "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
        "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
        "* When [saving a model's weights](./save_and_serialize.ipynb), `tf.keras` defaults to the\n",
        "  [checkpoint format](../checkpoint.ipynb). Pass `save_format='h5'` to\n",
        "  use HDF5 (or pass a filename that ends in `.h5`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e1LPcXx0gR6"
      },
      "source": [
        "## Build a simple model\n",
        "\n",
        "### Sequential model\n",
        "\n",
        "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
        "of layers. The most common type of model is a stack of layers: the\n",
        "`tf.keras.Sequential` model.\n",
        "\n",
        "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WM-DUVQB0E14"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add a softmax layer with 10 output units:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I2oH0-cxH7YA"
      },
      "source": [
        "You can find a complete, short example of how to use Sequential models [here](https://www.tensorflow.org/tutorials/quickstart/beginner).\n",
        "\n",
        "To learn about building more advanced models than Sequential models, see:\n",
        "- [Guide to the Keras Functional API](./functional.ipynb)\n",
        "- [Guide to writing layers and models from scratch with subclassing](./custom_layers_and_models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ztyTipu0E18"
      },
      "source": [
        "### Configure the layers\n",
        "\n",
        "There are many `tf.keras.layers` available. Most of them share some common constructor\n",
        "arguments:\n",
        "\n",
        "* `activation`: Set the activation function for the layer. This parameter is\n",
        "  specified by the name of a built-in function or as a callable object. By\n",
        "  default, no activation is applied.\n",
        "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
        "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
        "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
        "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
        "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
        "  regularization. By default, no regularization is applied.\n",
        "\n",
        "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
        "arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MlL7PBtp0E19"
      },
      "outputs": [],
      "source": [
        "# Create a sigmoid layer:\n",
        "layers.Dense(64, activation='sigmoid')\n",
        "# Or:\n",
        "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
        "\n",
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# A linear layer with a bias vector initialized to 2.0s:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9NR6reyk0E2A"
      },
      "source": [
        "## Train and evaluate\n",
        "\n",
        "### Set up training\n",
        "\n",
        "After the model is constructed, configure its learning process by calling the\n",
        "`compile` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sJ4AOn090E2A"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add a softmax layer with 10 output units:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HG-RAa9F0E2D"
      },
      "source": [
        "`tf.keras.Model.compile` takes three important arguments:\n",
        "\n",
        "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
        "  instances from the `tf.keras.optimizers` module, such as\n",
        "  `tf.keras.optimizers.Adam` or\n",
        "  `tf.keras.optimizers.SGD`. If you just want to use the default parameters, you can also specify optimizers via strings, such as `'adam'` or `'sgd'`.\n",
        "* `loss`: The function to minimize during optimization. Common choices include\n",
        "  mean square error (`mse`), `categorical_crossentropy`, and\n",
        "  `binary_crossentropy`. Loss functions are specified by name or by\n",
        "  passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. These are string names or callables from\n",
        "  the `tf.keras.metrics` module.\n",
        "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass `run_eagerly=True` as a parameter to compile.\n",
        "\n",
        "\n",
        "The following shows a few examples of configuring a model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "St4Mgdar0E2E"
      },
      "outputs": [],
      "source": [
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yjI5rbi80E2G"
      },
      "source": [
        "### Train from NumPy data\n",
        "\n",
        "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
        "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
        "using the `fit` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3CvP6L-m0E2I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-pnVaFe0E2N"
      },
      "source": [
        "`tf.keras.Model.fit` takes three important arguments:\n",
        "\n",
        "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
        "  the entire input data (this is done in smaller batches).\n",
        "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
        "  batches and iterates over these batches during training. This integer\n",
        "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
        "  if the total number of samples is not divisible by the batch size.\n",
        "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
        "  performance on some validation data. Passing this argument—a tuple of inputs\n",
        "  and labels—allows the model to display the loss and metrics in inference mode\n",
        "  for the passed data, at the end of each epoch.\n",
        "\n",
        "Here's an example using `validation_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gFcXzVQa0E2N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = np.random.random((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6ImyXzz0E2Q"
      },
      "source": [
        "### Train from tf.data datasets\n",
        "\n",
        "Use the [Datasets API](../data.ipynb) to scale to large datasets\n",
        "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
        "method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OziqhpIj0E2R"
      },
      "outputs": [],
      "source": [
        "# Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I7BcMHkB0E2U"
      },
      "source": [
        "Since the `Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
        "\n",
        "Datasets can also be used for validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YPMb3A0N0E2V"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10,\n",
        "          validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IgGdlXso0E2X"
      },
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "Here's how to *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mhDbOHEK0E2Y"
      },
      "outputs": [],
      "source": [
        "# With Numpy arrays\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "# With a Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.evaluate(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXUTmDfb0E2b"
      },
      "source": [
        "And here's how to *predict* the output of the last layer in inference for the data provided,\n",
        "as a NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9e3JsSoQ0E2c"
      },
      "outputs": [],
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GuTb71gYILLG"
      },
      "source": [
        "For a complete guide on training and evaluation, including how to write custom training loops from scratch, see the [guide to training and evaluation](./train_and_evaluate.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fzEOW4Cn0E2h"
      },
      "source": [
        "## Build complex models\n",
        "\n",
        "### The Functional API\n",
        "\n",
        " The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
        "represent arbitrary models. Use the\n",
        "[Keras functional API](./functional.ipynb)\n",
        "to build complex model topologies such as:\n",
        "\n",
        "* Multi-input models,\n",
        "* Multi-output models,\n",
        "* Models with shared layers (the same layer called several times),\n",
        "* Models with non-sequential data flows (e.g. residual connections).\n",
        "\n",
        "Building a model with the functional API works like this:\n",
        "\n",
        "1. A layer instance is callable and returns a tensor.\n",
        "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
        "   instance.\n",
        "3. This model is trained just like the `Sequential` model.\n",
        "\n",
        "The following example uses the functional API to build a simple, fully-connected\n",
        "network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mROj832r0E2i"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(32,))  # Returns an input placeholder\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor.\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFmspHeG1_W7"
      },
      "source": [
        "Instantiate the model given inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5k5uzlyu16HM"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EcKSLH3i0E2k"
      },
      "source": [
        "### Model subclassing\n",
        "\n",
        "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
        "your own forward pass. Create layers in the `__init__` method and set them as\n",
        "attributes of the class instance. Define the forward pass in the `call` method.\n",
        "\n",
        "Model subclassing is particularly useful when\n",
        "[eager execution](../eager.ipynb) is enabled, because it allows the forward pass\n",
        "to be written imperatively.\n",
        "\n",
        "Note: if you need your model to *always* run imperatively, you can set `dynamic=True` when calling the `super` constructor.\n",
        "\n",
        "\u003e Key Point: Use the right API for the job. While model subclassing offers\n",
        "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
        "user errors. If possible, prefer the functional API.\n",
        "\n",
        "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
        "pass that does not have to be run imperatively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KLiHWzcn2Fzk"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(MyModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # Define your layers here.\n",
        "    self.dense_1 = layers.Dense(32, activation='relu')\n",
        "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShDD4fv72KGc"
      },
      "source": [
        "Instantiate the new model class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "42C-qQHm0E2l"
      },
      "outputs": [],
      "source": [
        "model = MyModel(num_classes=10)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqRQiKj20E2o"
      },
      "source": [
        "### Custom layers\n",
        "\n",
        "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
        "the following methods:\n",
        "\n",
        "* `__init__`: Optionally define sublayers to be used by this layer.\n",
        "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
        "  method.\n",
        "* `call`: Define the forward pass.\n",
        "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
        "  and the `from_config` class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a `matmul` of an input with\n",
        "a kernel matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l7BFnIHr2WNc"
      },
      "outputs": [],
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=(input_shape[1], self.output_dim),\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8wXDRgXV2ZrF"
      },
      "source": [
        "Create a model using your custom layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uqH-cY0h0E2p"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    MyLayer(10),\n",
        "    layers.Activation('softmax')])\n",
        "\n",
        "# The compile step specifies the training configuration\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "llipvR5wIl_t"
      },
      "source": [
        "Learn more about creating new layers and models from scratch with subclassing in the [Guide to writing layers and models from scratch](./custom_layers_and_models.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lu8cc3AJ0E2v"
      },
      "source": [
        "## Callbacks\n",
        "\n",
        "A callback is an object passed to a model to customize and extend its behavior\n",
        "during training. You can write your own custom callback, or use the built-in\n",
        "`tf.keras.callbacks` that include:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
        "  regular intervals.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
        "  rate.\n",
        "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
        "  performance has stopped improving.\n",
        "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
        "  [TensorBoard](https://tensorflow.org/tensorboard).\n",
        "\n",
        "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rdYwzSYV0E2v"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  # Write TensorBoard logs to `./logs` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(val_data, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghhaGfX62abv"
      },
      "source": [
        "<a name='save_and_restore'></a>\n",
        "## Save and restore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qnl7K-aI0E2z"
      },
      "source": [
        "<a name=\"weights_only\"></a>\n",
        "### Save just the weights values\n",
        "\n",
        "Save and load the weights of a model using `tf.keras.Model.save_weights`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uQIANjB94fLB"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4eoHJ-ny0E21"
      },
      "outputs": [],
      "source": [
        "# Save weights to a TensorFlow Checkpoint file\n",
        "model.save_weights('./weights/my_model')\n",
        "\n",
        "# Restore the model's state,\n",
        "# this requires a model with the same architecture.\n",
        "model.load_weights('./weights/my_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u25Id3xe0E25"
      },
      "source": [
        "By default, this saves the model's weights in the\n",
        "[TensorFlow checkpoint](../checkpoint.ipynb) file format. Weights can\n",
        "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
        "implementation of Keras):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JSAYoFEd0E26"
      },
      "outputs": [],
      "source": [
        "# Save weights to a HDF5 file\n",
        "model.save_weights('my_model.h5', save_format='h5')\n",
        "\n",
        "# Restore the model's state\n",
        "model.load_weights('my_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mje_yKL10E29"
      },
      "source": [
        "### Save just the model configuration\n",
        "\n",
        "A model's configuration can be saved—this serializes the model architecture\n",
        "without any weights. A saved configuration can recreate and initialize the same\n",
        "model, even without the code that defined the original model. Keras supports\n",
        "JSON and YAML serialization formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EbET0oJTzGkq"
      },
      "outputs": [],
      "source": [
        "# Serialize a model to JSON format\n",
        "json_string = model.to_json()\n",
        "json_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pX_badhH3yWV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pprint\n",
        "pprint.pprint(json.loads(json_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7CIa05r4yTb"
      },
      "source": [
        "Recreate the model (newly initialized) from the JSON:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J9UFv9k00E2_"
      },
      "outputs": [],
      "source": [
        "fresh_model = tf.keras.models.model_from_json(json_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t5NHtICh4uHK"
      },
      "source": [
        "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aj24KB3Z36S4"
      },
      "outputs": [],
      "source": [
        "yaml_string = model.to_yaml()\n",
        "print(yaml_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O53Kerfl43v7"
      },
      "source": [
        "Recreate the model from the YAML:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "77yRuwg03_MG"
      },
      "outputs": [],
      "source": [
        "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xPvOSSzM0E3B"
      },
      "source": [
        "Caution: Subclassed models are not serializable because their architecture is\n",
        "defined by the Python code in the body of the `call` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iu8qMwld4-71"
      },
      "source": [
        "\n",
        "### Save the entire model in one file\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the\n",
        "model's configuration, and even the optimizer's configuration. This allows you\n",
        "to checkpoint a model and resume training later—from the exact same\n",
        "state—without access to the original code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "45oNY34Z0E3C"
      },
      "outputs": [],
      "source": [
        "# Create a simple model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(data, labels, batch_size=32, epochs=5)\n",
        "\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Recreate the exact same model, including weights and optimizer.\n",
        "model = tf.keras.models.load_model('my_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wGVBURDtI_I6"
      },
      "source": [
        "Learn more about saving and serialization for Keras models in the guide to [save and serialize models](./save_and_serialize.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PMOWhDOB0E3E"
      },
      "source": [
        "<a name=\"eager_execution\"></a>\n",
        "## Eager execution\n",
        "\n",
        "[Eager execution](../eager.ipynb) is an imperative programming\n",
        "environment that evaluates operations immediately. This is not required for\n",
        "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
        "debugging.\n",
        "\n",
        "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
        "And while the `Sequential` and functional APIs can be used, eager execution\n",
        "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
        "that require you to write the forward pass as code (instead of the APIs that\n",
        "create models by assembling existing layers).\n",
        "\n",
        "See the [eager execution guide](../eager.ipynb) for\n",
        "examples of using Keras models with custom training loops and `tf.GradientTape`.\n",
        "You can also find a complete, short example [here](https://www.tensorflow.org/tutorials/quickstart/advanced)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wG3NVco5B5V"
      },
      "source": [
        "## Distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PJZ6e9J5JHF"
      },
      "source": [
        "### Multiple GPUs\n",
        "\n",
        "`tf.keras` models can run on multiple GPUs using\n",
        "`tf.distribute.Strategy`. This API provides distributed\n",
        "training on multiple GPUs with almost no changes to existing code.\n",
        "\n",
        "Currently, `tf.distribute.MirroredStrategy` is the only supported\n",
        "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
        "synchronous training using all-reduce on a single machine. To use\n",
        "`distribute.Strategy`s , nest the optimizer instantiation and model construction and compilation in a `Strategy`'s `.scope()`, then\n",
        "train the model.\n",
        "\n",
        "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
        "single machine.\n",
        "\n",
        "First, define a model inside the distributed strategy scope:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sbaRr7g-0E3I"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = tf.keras.optimizers.SGD(0.2)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rO9MiL6X0E3O"
      },
      "source": [
        "Next, train the model on data as usual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BEwFq4PM0E3P"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((1024, 10))\n",
        "y = np.random.randint(2, size=(1024, 1))\n",
        "x = tf.cast(x, tf.float32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6BXU5F90E3U"
      },
      "source": [
        "For more information, see the [full guide on Distributed Training in TensorFlow](../distributed_training.ipynb)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "overview.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}, 

SwiftUI
 
Tutorials
Open Menu




SwiftUI Essentials
Building Lists and Navigation
With the basic landmark detail view set up, you need to provide a way for users to see the full list of landmarks, and to view the details about each location.

You’ll create views that can show information about any landmark, and dynamically generate a scrolling list that a user can tap to see a detail view for a landmark. To fine-tune the UI, you’ll use Xcode’s canvas to render multiple previews at different device sizes.

Download the project files to begin building this project, and follow the steps below.

35min
Estimated Time
Project files
Xcode 11
Section 1
Get to Know the Sample Data
In the first tutorial, you hard-coded information into all of your custom views. Here, you’ll learn to pass data into your custom views for display.

Get started by downloading the starter project and familiarizing yourself with the sample data.

A diagram that shows how details about various landmarks are culled from JSON data.
Step 1

In the Project navigator, choose Models > Landmark.swift.

Landmark.swift declares a Landmark structure that stores all of the landmark information the app needs to display, and imports an array of landmark data from landmarkData.json.

Swift file iconLandmark.swift
import SwiftUI
import CoreLocation

struct Landmark: Hashable, Codable {
    var id: Int
    var name: String
    fileprivate var imageName: String
    fileprivate var coordinates: Coordinates
    var state: String
    var park: String
    var category: Category

    var locationCoordinate: CLLocationCoordinate2D {
        CLLocationCoordinate2D(
            latitude: coordinates.latitude,
            longitude: coordinates.longitude)
    }

    enum Category: String, CaseIterable, Codable, Hashable {
        case featured = "Featured"
        case lakes = "Lakes"
        case rivers = "Rivers"
    }
}

extension Landmark {
    var image: Image {
        ImageStore.shared.image(name: imageName)
    }
}

struct Coordinates: Hashable, Codable {
    var latitude: Double
    var longitude: Double
}
No preview 
Step 2

In the Project navigator, choose Resources > landmarkData.json.

You’ll use this sample data throughout the remainder of this tutorial, and for all that follow.

Generic file iconlandmarkData.json
[
    {
        "name": "Turtle Rock",
        "category": "Featured",
        "city": "Twentynine Palms",
        "state": "California",
        "id": 1001,
        "park": "Joshua Tree National Park",
        "coordinates": {
            "longitude": -116.166868,
            "latitude": 34.011286
        },
        "imageName": "turtlerock"
    },
    {
        "name": "Silver Salmon Creek",
        "category": "Lakes",
        "city": "Port Alsworth",
        "state": "Alaska",
        "id": 1002,
        "park": "Lake Clark National Park and Preserve",
        "coordinates": {
            "longitude": -152.665167,
            "latitude": 59.980167
        },
        "imageName": "silversalmoncreek"
    },
    ...
]
No preview 
Step 3

Note that the ContentView type from Creating and Combining Views is now named LandmarkDetail.

You’ll create several more view types in this and each of the following tutorials.

Swift file iconLandmarkDetail.swift
import SwiftUI

struct LandmarkDetail: View {
    var body: some View {
        VStack {
            MapView()
                .frame(height: 300)

            CircleImage()
                .offset(y: -130)
                .padding(.bottom, -130)

            VStack(alignment: .leading) {
                Text("Turtle Rock")
                    .font(.title)

                HStack(alignment: .top) {
                    Text("Joshua Tree National Park")
                        .font(.subheadline)
                    Spacer()
                    Text("California")
                        .font(.subheadline)
                }
            }
            .padding()

            Spacer()
        }
    }
}

struct LandmarkDetail_Preview: PreviewProvider {
    static var previews: some View {
        LandmarkDetail()
    }
}
Preview 
Section 2
Create the Row View
The first view you’ll build in this tutorial is a row for displaying details about each landmark. This row view stores information in a property for the landmark it displays, so that one view can display any landmark. Later, you’ll combine multiple rows into a list of landmarks.

A diagram that depicts how the row you'll build for this tutorial is constructed. The row consists of an image at left, a text view that pulls data from the JSON file for details about the landmark, and a spacer to the right.
Step 1

Create a new SwiftUI view, named LandmarkRow.swift.

A screenshot of Xcode, showing the file creation dialog.
Step 2

If the preview isn’t visible already, show the canvas by selecting Editor > Editor and Canvas, and then click Get Started.

An image that shows the Welcome to SwiftUI screen in Xcode.
Step 3

Add landmark as a stored property of LandmarkRow.

When you add the landmark property, the preview stops working, because the LandmarkRow type needs a landmark instance during initialization.

Swift file iconLandmarkRow.swift

struct LandmarkRow: View {
    var landmark: Landmark

    var body: some View {
        Text("Hello World")
No preview 
To fix the preview, you’ll need to modify the preview provider.

Step 4

In the previews static property of LandmarkRow_Previews, add the landmark parameter to the LandmarkRow initializer, specifying the first element of the landmarkData array.

The preview displays the text, Hello World.

Swift file iconLandmarkRow.swift
struct LandmarkRow_Previews: PreviewProvider {
    static var previews: some View {
        LandmarkRow(landmark: landmarkData[0])
    }
}
Preview 
With that fixed, you can build the layout for the row.

Step 5

Embed the existing text view in an HStack.

Swift file iconLandmarkRow.swift

    var body: some View {
        HStack {
            Text("Hello World")
        }
    }
}
Preview 
Step 6

Modify the text view to use the landmark property’s name.

Swift file iconLandmarkRow.swift
    var body: some View {
        HStack {
            Text(landmark.name)
        }
    }
Preview 
Step 7

Complete the row by adding an image before the text view.

Swift file iconLandmarkRow.swift
    var body: some View {
        HStack {
            landmark.image
                .resizable()
                .frame(width: 50, height: 50)
            Text(landmark.name)
        }
Preview 
Section 3
Customize the Row Preview
Xcode’s canvas automatically recognizes and displays any type in the current editor that conforms to the PreviewProvider protocol. A preview provider returns one or more views, with options to configure the size and device.

You can customize the returned content from a preview provider to render exactly the previews that are most helpful to you.

An image of two iPhone devices side-by-side. The iPhone on the left has a higlight around four rows near the middle of the display. There is an arrow from the four highlighted rows on the left, which are replicated in a list view on the right iPhone.
Step 1

In LandmarkRow_Previews, update the landmark parameter to be the second element in the landmarkData array.

The preview immediately changes to show the second sample landmark instead of the first.

Swift file iconLandmarkRow.swift
struct LandmarkRow_Previews: PreviewProvider {
    static var previews: some View {
        LandmarkRow(landmark: landmarkData[1])
    }
}
Preview 
Step 2

Use the previewLayout(_:) modifier to set a size that approximates a row in a list.

Swift file iconLandmarkRow.swift
    static var previews: some View {
        LandmarkRow(landmark: landmarkData[1])
            .previewLayout(.fixed(width: 300, height: 70))
    }
}
Preview 
You can use a Group to return multiple previews from a preview provider.

Step 3

Wrap the returned row in a Group, and add the first row back again.

Group is a container for grouping view content. Xcode renders the group’s child views as separate previews in the canvas.

Swift file iconLandmarkRow.swift
struct LandmarkRow_Previews: PreviewProvider {
    static var previews: some View {
        Group {
            LandmarkRow(landmark: landmarkData[0])
                .previewLayout(.fixed(width: 300, height: 70))
            LandmarkRow(landmark: landmarkData[1])
                .previewLayout(.fixed(width: 300, height: 70))
        }
    }
}
Preview 
Step 4

To simplify the code, move the previewLayout(_:) call to the outside of the group’s child declarations.

A view’s children inherit the view’s contextual settings, such as preview configurations.

Swift file iconLandmarkRow.swift
            LandmarkRow(landmark: landmarkData[1])
        }
        .previewLayout(.fixed(width: 300, height: 70))
    }
}
Preview 
The code you write in a preview provider only changes what Xcode displays in the canvas.

Section 4
Create the List of Landmarks
When you use SwiftUI’s List type, you can display a platform-specific list of views. The elements of the list can be static, like the child views of the stacks you’ve created so far, or dynamically generated. You can even mix static and dynamically generated views.

A screenshot of two landmark rows, complete with images on the left, the landmark name, and navigational arrows on the right edge of each row.
Step 1

Create a new SwiftUI view, named LandmarkList.swift.

A screenshot of Xcode, showing the new SwiftUI view being added to the project.
Step 2

Replace the default Text view with a List, and provide LandmarkRow instances with the first two landmarks as the list’s children.

The preview shows the two landmarks rendered in a list style that’s appropriate for iOS.

Swift file iconLandmarkList.swift
struct LandmarkList: View {
    var body: some View {
        List {
            LandmarkRow(landmark: landmarkData[0])
            LandmarkRow(landmark: landmarkData[1])
        }
    }
}
Preview 
Section 5
Make the List Dynamic
Instead of specifying a list’s elements individually, you can generate rows directly from a collection.

You can create a list that displays the elements of collection by passing your collection of data and a closure that provides a view for each element in the collection. The list transforms each element in the collection into a child view by using the supplied closure.

A diagram that depicts JSON data being flowed into rows that make up the navigation for the Landmarks app.
Step 1

Remove the two static landmark rows, and instead pass landmarkData to the List initializer.

Lists work with identifiable data. You can make your data identifiable in one of two ways: by passing along with your data a key path to a property that uniquely identifies each element, or by making your data type conform to the Identifiable protocol.

Swift file iconLandmarkList.swift
struct LandmarkList: View {
    var body: some View {
        List(landmarkData, id: \.id) { landmark in

        }
    }
No preview 
Step 2

Complete the dynamically-generated list by returning a LandmarkRow from the closure.

This creates one LandmarkRow for each element in the landmarkData array.

Swift file iconLandmarkList.swift
    var body: some View {
        List(landmarkData, id: \.id) { landmark in
            LandmarkRow(landmark: landmark)
        }
    }
Preview 
Next, you’ll simplify the List code by adding Identifiable conformance to the Landmark type.

Step 3

Switch to Landmark.swift and declare conformance to the Identifiable protocol.

Since the Landmark type already has the id property required by Identifiable protocol, there’s no more work to do.

Swift file iconLandmark.swift
import CoreLocation

struct Landmark: Hashable, Codable, Identifiable {
    var id: Int
    var name: String
Preview 
Step 4

Switch back to LandmarkList.swift and remove the id parameter.

From now on, you’ll be able to use collections of Landmark elements directly.

Swift file iconLandmarkList.swift
struct LandmarkList: View {
    var body: some View {
        List(landmarkData) { landmark in
            LandmarkRow(landmark: landmark)
        }
Preview 
Section 6
Set Up Navigation Between List and Detail
The list renders properly, but you can’t tap an individual landmark to see that landmark’s detail page yet.

You add navigation capabilities to a list by embedding it in a NavigationView, and then nesting each row in a NavigationLink to set up a transtition to a destination view.

An image of two iPhone devices side by side. The left iPhone shows a list of landmarks, with a highlight around the first row. An arrow is drawn from the highlighted row to the iPhone on the right, which displays the detail view for the selected landmark.
Step 1

Embed the dynamically generated list of landmarks in a NavigationView.

Swift file iconLandmarkList.swift
struct LandmarkList: View {
    var body: some View {
        NavigationView {
            List(landmarkData) { landmark in
                LandmarkRow(landmark: landmark)
            }
        }
    }
Preview 
Step 2

Call the navigationBarTitle(_:) modifier method to set the title of the navigation bar when displaying the list.

Swift file iconLandmarkList.swift
                LandmarkRow(landmark: landmark)
            }
            .navigationBarTitle(Text("Landmarks"))
        }
    }
Preview 
Step 3

Inside the list’s closure, wrap the returned row in a NavigationLink, specifying the LandmarkDetail view as the destination.

Swift file iconLandmarkList.swift
        NavigationView {
            List(landmarkData) { landmark in
                NavigationLink(destination: LandmarkDetail()) {
                    LandmarkRow(landmark: landmark)
                }
            }
            .navigationBarTitle(Text("Landmarks"))
Preview 
Step 4

You can try out the navigation directly in the preview by switching to live mode. Click the Live Preview button and tap a landmark to visit the detail page.

A screenshot of an iPhone SE from Simulator, showing the navigational view of the Landmarks app. Each landmark row has an image on the left, followed by the landmark name, with a navigation arrow on the right edge of each row.
Section 7
Pass Data into Child Views
The LandmarkDetail view still uses hard-coded details to show its landmark. Just like LandmarkRow, the LandmarkDetail type and the views it comprises need to use a landmark property as the source for their data.

Starting with the child views, you’ll convert CircleImage, MapView, and then LandmarkDetail to display data that’s passed in, rather than hard-coding each row.

A diagram of a landmark's detail view, showing data for the landmark, image name, and the landmark's coordinates.
Step 1

In CircleImage.swift, add a stored image property to CircleImage.

This is a common pattern when building views using SwiftUI. Your custom views will often wrap and encapsulate a series of modifiers for a particular view.

Swift file iconCircleImage.swift

struct CircleImage: View {
    var image: Image

    var body: some View {
        image
No preview 
Step 2

Update the preview provider to pass the image of Turtle Rock.

Swift file iconCircleImage.swift
struct CircleImage_Preview: PreviewProvider {
    static var previews: some View {
        CircleImage(image: Image("turtlerock"))
    }
}
No preview 
Step 3

In MapView.swift, add a coordinate property to MapView and convert the code to use that property instead of hard-coding the latitude and longitude.

Swift file iconMapView.swift

struct MapView: UIViewRepresentable {
    var coordinate: CLLocationCoordinate2D

    func makeUIView(context: Context) -> MKMapView {
        MKMapView(frame: .zero)
No preview 
Step 4

Update the preview provider to pass the coordinate of the first landmark in the data array.

Swift file iconMapView.swift
struct MapView_Preview: PreviewProvider {
    static var previews: some View {
        MapView(coordinate: landmarkData[0].locationCoordinate)
    }
}
No preview 
Step 5

In LandmarkDetail.swift, add a Landmark property to the LandmarkDetail type.

Swift file iconLandmarkDetail.swift

struct LandmarkDetail: View {
    var landmark: Landmark

    var body: some View {
        VStack {
No preview 
Step 6

Update the preview to use the first landmark from landmarkData.

Swift file iconLandmarkDetail.swift
struct LandmarkDetail_Preview: PreviewProvider {
    static var previews: some View {
        LandmarkDetail(landmark: landmarkData[0])
    }
}
No preview 
Step 7

Pass the required data down to your custom types.

Swift file iconLandmarkDetail.swift
    var body: some View {
        VStack {
            MapView(coordinate: landmark.locationCoordinate)
                .frame(height: 300)

No preview 
Step 8

Finally, call the navigationBarTitle(_:displayMode:) modifier to give the navigation bar a title when showing the detail view.

Swift file iconLandmarkDetail.swift
            Spacer()
        }
        .navigationBarTitle(Text(landmark.name), displayMode: .inline)
    }
}
No preview 
Step 9

In SceneDelegate.swift, switch the root view of the app to be LandmarkList.

Your app starts with the root view defined in the SceneDelegate when running standalone in the simulator instead of the preview.

Swift file iconSceneDelegate.swift
        if let windowScene = scene as? UIWindowScene {
            let window = UIWindow(windowScene: windowScene)
            window.rootViewController = UIHostingController(rootView: LandmarkList())
            self.window = window
            window.makeKeyAndVisible()
Preview 
Step 10

In LandmarkList.swift, pass the current landmark to the destination LandmarkDetail.

Swift file iconLandmarkList.swift
        NavigationView {
            List(landmarkData) { landmark in
                NavigationLink(destination: LandmarkDetail(landmark: landmark)) {
                    LandmarkRow(landmark: landmark)
                }
Preview 
Step 11

Switch to the live preview to see the detail view show the correct landmarks when you navigate from the list.

A screenshot of an iPhone SE from Simulator, showing the navigational view of the Landmarks app. Each landmark row has an image on the left, followed by the landmark name, with a navigation arrow on the right edge of each row.
Section 8
Generating Previews Dynamically
Next, you’ll add code to the LandmarkList_Previews preview provider to render previews of the list view at different device sizes. By default, previews render at the size of the device in the active scheme. You can change the preview device by calling the previewDevice(_:) modifier method.

A diagram showing a landmark list view on the left flowing into an iPhone XR in the middle, and to an iPhone XR Max to the right. This series of images depicts how SwiftUI scales the same views appropriately for each device type.
Step 1

Start by changing the current list preview to render at the size of an iPhone SE.

You can provide the name of any device as it appears in Xcode’s scheme menu.

Swift file iconLandmarkList.swift
    static var previews: some View {
        LandmarkList()
            .previewDevice(PreviewDevice(rawValue: "iPhone SE"))
    }
}
Preview 
Step 2

Within the list preview, embed the LandmarkList in a ForEach instance, using an array of device names as the data.

ForEach operates on collections the same way as the list, which means you can use it anywhere you can use a child view, such as in stacks, lists, groups, and more. When the elements of your data are simple value types — like the strings you’re using here — you can use \.self as key path to the identifier.

Swift file iconLandmarkList.swift
struct LandmarkList_Previews: PreviewProvider {
    static var previews: some View {
        ForEach(["iPhone SE", "iPhone XS Max"], id: \.self) { deviceName in
            LandmarkList()
                .previewDevice(PreviewDevice(rawValue: deviceName))
        }
    }
}
Preview 
Step 3

Use the previewDisplayName(_:) modifier to add the device names as labels for the previews.

Swift file iconLandmarkList.swift
            LandmarkList()
                .previewDevice(PreviewDevice(rawValue: deviceName))
                .previewDisplayName(deviceName)
        }
    }
Preview 
Step 4

You can experiment with different devices to compare the renderings of your views, all from the canvas.

A screenshot of the Xcode Preview, showing two different-sized versions of the Landmarks navigational screen stacked on top of each other. The device on top is labeled iPhone XS Max, and the device on bottom is labeled iPad Pro (12.9-inch).
Check Your Understanding
Question 1 of 4

In addition to List, which of these types presents a dynamic list of views from a collection?


Group


ForEach


UITableView

Submit Next Question
Next
Handling User Input
In the Landmarks app, a user can flag their favorite places, and filter the list to show just their favorites. To create this feature, you’ll start by adding a switch to the list so users can focus on just their favorites, and then you’ll add a star-shaped button that a user taps to flag a landmark as a favorite.

Get started

Developer
To receive the latest developer news, visit and subscribe to our News and Updates.
Copyright © 2019 Apple Inc. All rights reserved.Terms of Use Privacy Policy Report Bugs Feedback
简体中文 日本語 한국어

Swift file iconLandmark.swift
import SwiftUI
import CoreLocation

struct Landmark: Hashable, Codable {
    var id: Int
    var name: String
    fileprivate var imageName: String
    fileprivate var coordinates: Coordinates
    var state: String
    var park: String
    var category: Category

    var locationCoordinate: CLLocationCoordinate2D {
        CLLocationCoordinate2D(
            latitude: coordinates.latitude,
            longitude: coordinates.longitude)
    }

    enum Category: String, CaseIterable, Codable, Hashable {
        case featured = "Featured"
        case lakes = "Lakes"
        case rivers = "Rivers"
    }
}

extension Landmark {
    var image: Image {
        ImageStore.shared.image(name: imageName)
    }
}

struct Coordinates: Hashable, Codable {
    var latitude: Double
    var longitude: Double
}
