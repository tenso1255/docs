{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Functions and Autograph",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "Jxv6goXm7oGF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Jxv6goXm7oGF"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "llMNufAK7nfK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8Byow2J6LaPl"
      },
      "cell_type": "markdown",
      "source": [
        "# tf.function and AutoGraph in TensorFlow 2.0"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kGXS3UWBBNoc"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/2/guide/autograph\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/guide/autograph.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/autograph.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CydFK2CL7ZHA"
      },
      "cell_type": "markdown",
      "source": [
        "TF 2.0 brings together the ease of eager execution and the power of TF 1.0. At the center of this merger is `tf.function`, which allows you to transform a subset of Python syntax into portable, high-performance TensorFlow graphs.\n",
        "\n",
        "A cool new feature of `tf.function` is AutoGraph, which lets you write graph code using natural Python syntax. For a list of the Python features that you can use with AutoGraph, see [AutoGraph Capabilities and Limitations](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md). For more details about `tf.function`, see the RFC [TF 2.0: Functions, not Sessions](https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md). For more details about AutoGraph, see `tf.autograph`.\n",
        "\n",
        "This tutorial will walk you through the basic features of `tf.function` and AutoGraph."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n4EKOpw9mObL"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Import TensorFlow 2.0 Preview Nightly and enable TF 2.0 mode:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V9oECvVSI1Kj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mT7meGqrZTz9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tf-nightly-2.0-preview\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ypIdFDCTfjLj"
      },
      "cell_type": "markdown",
      "source": [
        "Install a temporary patch to enable a few extra TF 2.0 upgrades. This piece will be removed soon."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IfgTXZETfQ4u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops import control_flow_util\n",
        "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "77AsVr1GGtBP"
      },
      "cell_type": "markdown",
      "source": [
        "## The `tf.function` decorator\n",
        "\n",
        "When you annotate a function with `tf.function`, you can still call it like any other function. But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FhIg7-z6HNWj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def simple_nn_layer(x, y):\n",
        "  return tf.nn.relu(tf.matmul(x, y))\n",
        "\n",
        "\n",
        "x = tf.random.uniform((3, 3))\n",
        "y = tf.random.uniform((3, 3))\n",
        "\n",
        "simple_nn_layer(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U-LAE4pMNR9g"
      },
      "cell_type": "markdown",
      "source": [
        "If we examine the result of the annotation, we can see that it's a special callable that handles all interactions with the TensorFlow runtime. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q4t2iuS7Nqc0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "simple_nn_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DqeefLGNXjZQ"
      },
      "cell_type": "markdown",
      "source": [
        "If your code uses multiple functions, you don't need to annotate them all - any functions called from an annotated function will also run in graph mode."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3VGF7tlVXiZY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_layer(x):\n",
        "  return 2 * x + 1\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def deep_net(x):\n",
        "  return tf.nn.relu(linear_layer(x))\n",
        "\n",
        "\n",
        "deep_net(tf.constant((1, 2, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ohbSnA79mcJV"
      },
      "cell_type": "markdown",
      "source": [
        "## Use Python control flow\n",
        "\n",
        "When using data-dependent control flow inside `tf.function`, you can use Python control flow statements and AutoGraph will convert them into appropriate TensorFlow ops. For example, `if` statements will be converted into `tf.cond()` if they depend on a `Tensor`.\n",
        "\n",
        "In the example below, `x` is a `Tensor` but the `if` statement works as expected:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aA3gOodCBkOw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def square_if_positive(x):\n",
        "  if x > 0:\n",
        "    x = x * x\n",
        "  else:\n",
        "    x = 0\n",
        "  return x\n",
        "\n",
        "\n",
        "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
        "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GMiCUkdyoq98"
      },
      "cell_type": "markdown",
      "source": [
        "Note: the example above shows how to perform simple conditionals when scalar values are involves. Typical ML code involves batches; in those cases you should consider using the faster and vectorized `tf.where` if possible. Below is a `tf.where` version of the example above."
      ]
    },
    {
      "metadata": {
        "id": "rX2XRr8iXgiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def square_if_positive(x):\n",
        "  return tf.where(x > 0, x * x, 0)\n",
        "\n",
        "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
        "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "m-jWmsCmByyw"
      },
      "cell_type": "markdown",
      "source": [
        "AutoGraph supports common Python statements like `while`, `for`, `if`, `break`, `continue` and `return`, with support for nesting. That means you can use `Tensor` expressions in the condition of `while` and `if` statements, or iterate over a `Tensor` in a `for` loop."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "toxKBOXbB1ro",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def sum_even(items):\n",
        "  s = 0\n",
        "  for c in items:\n",
        "    if c % 2 > 0:\n",
        "      continue\n",
        "    s += c\n",
        "  return s\n",
        "\n",
        "\n",
        "sum_even(tf.constant([10, 12, 15, 20]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AtDaLrbySw4j"
      },
      "cell_type": "markdown",
      "source": [
        "AutoGraph also provides a low-level API for advanced users. For example we can use it to have a look at the generated code."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aRsde3x_SjTQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.autograph.to_code(sum_even.python_function, experimental_optional_features=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rvJXCfk8VkLf"
      },
      "cell_type": "markdown",
      "source": [
        "Here's an example of more complicated control flow:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h-Z87IJqVlKl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def fizzbuzz(n):\n",
        "  msg = tf.constant('')\n",
        "  for i in tf.range(n):\n",
        "    if tf.equal(i % 3, 0):\n",
        "      msg += 'Fizz'\n",
        "    elif tf.equal(i % 5, 0):\n",
        "      msg += 'Buzz'\n",
        "    else:\n",
        "      msg += tf.as_string(i)\n",
        "    msg += '\\n'\n",
        "  return msg\n",
        "\n",
        "\n",
        "print(fizzbuzz(tf.constant(15)).numpy().decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "h_Y4uC1R1B55"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras and AutoGraph\n",
        "\n",
        "You can use `tf.function` with object methods as well. For example, you can decorate your custom Keras models, typically by annotating the model's `call` function. For more information, see `tf.keras`."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cR6mpLKP1HLe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.models.Model):\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, input_data):\n",
        "    if tf.reduce_mean(input_data) > 0:\n",
        "      return input_data\n",
        "    else:\n",
        "      return input_data // 2\n",
        "\n",
        "\n",
        "model = CustomModel()\n",
        "\n",
        "model(tf.constant([-2, -4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NTEvpBK9f8kj"
      },
      "cell_type": "markdown",
      "source": [
        "## Side effects\n",
        "\n",
        "Just like in eager mode, you can use operations with side effects, like `tf.assign` or `tf.print` normally inside `tf.function`, and it will insert the necessary control dependencies to ensure they execute in order."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-Wd6i8S9gcuC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v = tf.Variable(5)\n",
        "\n",
        "@tf.function\n",
        "def find_next_odd():\n",
        "  v.assign(v + 1)\n",
        "  if tf.equal(v % 2, 0):\n",
        "    v.assign(v + 1)\n",
        "\n",
        "\n",
        "find_next_odd()\n",
        "v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4LfnJjm0Bm0B"
      },
      "cell_type": "markdown",
      "source": [
        "## Example: training a simple model\n",
        "\n",
        "AutoGraph also allows you to move more computation inside TensorFlow. For example, a training loop is just control flow, so it can actually be brought into TensorFlow."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Em5dzSUOtLRP"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xqoxumv0ssQW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_mnist_features_and_labels(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 255.0\n",
        "  y = tf.cast(y, tf.int64)\n",
        "  return x, y\n",
        "\n",
        "def mnist_dataset():\n",
        "  (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
        "  ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  ds = ds.map(prepare_mnist_features_and_labels)\n",
        "  ds = ds.take(20000).shuffle(20000).batch(100)\n",
        "  return ds\n",
        "\n",
        "train_dataset = mnist_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "znmy4l8ntMvW"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ltxyJVWTqNAO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential((\n",
        "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)))\n",
        "model.build()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oeYV6mKnJGMr"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3xtg_MMhJETd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "\n",
        "def train_one_step(model, optimizer, x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    loss = compute_loss(y, logits)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  compute_accuracy(y, logits)\n",
        "  return loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train(model, optimizer):\n",
        "  train_ds = mnist_dataset()\n",
        "  step = 0\n",
        "  loss = 0.0\n",
        "  accuracy = 0.0\n",
        "  for x, y in train_ds:\n",
        "    step += 1\n",
        "    loss = train_one_step(model, optimizer, x, y)\n",
        "    if tf.equal(step % 10, 0):\n",
        "      tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n",
        "  return step, loss, accuracy\n",
        "\n",
        "step, loss, accuracy = train(model, optimizer)\n",
        "print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SnsumiP6eRYL"
      },
      "cell_type": "markdown",
      "source": [
        "## A note on batching\n",
        "\n",
        "In real applications batching is essential for performance. The best code to convert to AutoGraph is code where the control flow is decided at the _batch_ level. If making decisions at the individual _example_ level, try to use batch APIs to maintain performance.\n",
        "\n",
        "For example, if you have the following code in Python:\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t31QoERiNccJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def square_if_positive(x):\n",
        "  return [i ** 2 if i > 0 else i for i in x]\n",
        "\n",
        "\n",
        "square_if_positive(range(-5, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kSeEJ76uNgwD"
      },
      "cell_type": "markdown",
      "source": [
        "You may be tempted to write it in TensorFlow as such (and this would work!):\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RqR8WzSzNf87",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def square_if_positive_naive(x):\n",
        "  result = tf.TensorArray(tf.int32, size=x.shape[0])\n",
        "  for i in tf.range(x.shape[0]):\n",
        "    if x[i] > 0:\n",
        "      result = result.write(i, x[i] ** 2)\n",
        "    else:\n",
        "      result = result.write(i, x[i])\n",
        "  return result.stack()\n",
        "\n",
        "\n",
        "square_if_positive_naive(tf.range(-5, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gTcyWXVGN3gS"
      },
      "cell_type": "markdown",
      "source": [
        "But in this case, it turns out you can write the following:\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VO2f6x-lNfVj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def square_if_positive_vectorized(x):\n",
        "  return tf.where(x > 0, x ** 2, x)\n",
        "\n",
        "\n",
        "square_if_positive_vectorized(tf.range(-5, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xixU7eix5MRw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}